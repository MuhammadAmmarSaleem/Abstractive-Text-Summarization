{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCVhxCUcvuCm",
        "outputId": "a0e714e7-6f0b-41e3-fa07-60ad947073a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "T0dusgUNz0gw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj9ws2zG0B2h",
        "outputId": "7077fe5a-aac1-45c1-8ca9-5450fd2e1caa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading amazon-fine-food-reviews.zip to /content\n",
            " 96% 233M/242M [00:02<00:00, 138MB/s]\n",
            "100% 242M/242M [00:02<00:00, 107MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "U60_aylR1TeR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/amazon-fine-food-reviews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zR9tFUG1bcy",
        "outputId": "c57bc9d8-872f-42b2-8a8f-c24974bea2c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/amazon-fine-food-reviews.zip\n",
            "  inflating: Reviews.csv             \n",
            "  inflating: database.sqlite         \n",
            "  inflating: hashes.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/Reviews.csv\", encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "lPiBghgj11i7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lHQWV9vHak_p",
        "outputId": "59cfd6a4-b5c6-46d8-9276-ffdfaa9b0674"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary  \\\n",
              "0  Good Quality Dog Food   \n",
              "1      Not as Advertised   \n",
              "2  \"Delight\" says it all   \n",
              "3         Cough Medicine   \n",
              "4            Great taffy   \n",
              "\n",
              "                                                                                                                                                                                                      Text  \n",
              "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  \n",
              "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
              "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...  \n",
              "3  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  \n",
              "4                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207fb779-472e-444f-ae01-7c0dee09b477\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207fb779-472e-444f-ae01-7c0dee09b477')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207fb779-472e-444f-ae01-7c0dee09b477 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207fb779-472e-444f-ae01-7c0dee09b477');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "metadata": {
        "id": "bPomy5BR179y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9E7GlPB1_Wz",
        "outputId": "60c0efdd-89cb-40b0-fadc-f994b1441ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4396 entries, 0 to 4513\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   author     4396 non-null   object\n",
            " 1   date       4396 non-null   object\n",
            " 2   headlines  4396 non-null   object\n",
            " 3   read_more  4396 non-null   object\n",
            " 4   text       4396 non-null   object\n",
            " 5   ctext      4396 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 240.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "TGOfgkiG2J3G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 \n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrVBk6FQ2LiY",
        "outputId": "6af61395-dfe6-428e-c7de-8e2225fe3c5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) \n",
        "cleaned_text[:5]"
      ],
      "metadata": {
        "id": "F2qt7BNb2hql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4fa520-b010-4b27-9b9e-606ea1a65083"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))\n",
        "cleaned_summary[:10]"
      ],
      "metadata": {
        "id": "Jv-VZFVI22LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a56d2ba-1bac-4eec-b1db-e3dba12ef76b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "metadata": {
        "id": "Ij2wPtYT29nD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "d0EmvtfI3AmS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "w0Qaaqj8IE90",
        "outputId": "cdaa7491-1d43-4158-e21f-4b60143f2a61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_text_len=80\n",
        "max_summary_len=15"
      ],
      "metadata": {
        "id": "o_tMREfY3Cp4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "metadata": {
        "id": "KbLKK_ar3G_R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "metadata": {
        "id": "wWJ054ll3KfR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "metadata": {
        "id": "KLDMmdSv3NR5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "metadata": {
        "id": "KmPf8z1d3P5x"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYmRVLtk3Y-s",
        "outputId": "7b851b16-36be-454f-d01e-efdc44c0670e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 67.92538279059737\n",
            "Total Coverage of rare words: 0.8792769896221291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "metadata": {
        "id": "3L1mNKps3e3u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "metadata": {
        "id": "81XeNEii3g3s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSu-3CQ63j8q",
        "outputId": "cf1eb8d3-73f7-4468-f845-920bf56ccea8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 74.57301526317627\n",
            "Total Coverage of rare words: 1.8955462216834504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "metadata": {
        "id": "9SlPCFwR3nXs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUmDds0b3qp2",
        "outputId": "ca39f844-8cab-4022-d2f8-790f1da3256d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(322725, 322725)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "metadata": {
        "id": "CZXT1RAi3s9C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "metadata": {
        "id": "v_bu62-g3vvz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/attention.py\""
      ],
      "metadata": {
        "id": "MNBNY3KtkS5s"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tu1Gylyq5PW",
        "outputId": "926b1c51-b45b-4371-f5f0-788fb5b6853b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attention\n",
            "  Downloading attention-4.1-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from attention) (1.21.6)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.8/dist-packages (from attention) (2.9.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (0.29.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (2.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (21.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (2.9.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.1->attention) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1->attention) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.1->attention) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (5.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.2.2)\n",
            "Installing collected packages: attention\n",
            "Successfully installed attention-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "#attn_layer = Attention(name='attention_layer')\n",
        "#attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, decoder_outputs])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfXlZ9ROpinE",
        "outputId": "f1a3f549-b7be-40af-e611-ecae27a6581b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 80)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 80, 100)      2974700     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 80, 300),    481200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 80, 300),    721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    728100      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 80, 300),    721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 7281)  4375881     ['concat_layer[0][0]']           \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,483,481\n",
            "Trainable params: 10,483,481\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "from attention import AttentionLayer\n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "Attention_layer, attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "RqwdTHycli9r",
        "outputId": "1ef3330d-ff42-486a-84e2-eb3cbccf5df4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-67831aefe121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AttentionLayer' from 'attention' (/content/attention.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "from attention import AttentionLayer\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ncX45E6K3yS3",
        "outputId": "9b893648-ccb9-46a1-b1f3-8655410cacd9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b324116071a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AttentionLayer' from 'attention' (/content/attention.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "nyh37Ndp5El_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "metadata": {
        "id": "r0Kpulkk5FpA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=3,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUXPDn025H3R",
        "outputId": "a2fc5f45-79ad-42d6-f28d-bbcc71b5033a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2497/2497 [==============================] - 2811s 1s/step - loss: 1.6453 - val_loss: 1.5252\n",
            "Epoch 2/3\n",
            "2497/2497 [==============================] - 2698s 1s/step - loss: 1.4722 - val_loss: 1.4329\n",
            "Epoch 3/3\n",
            "2497/2497 [==============================] - 2668s 1s/step - loss: 1.4158 - val_loss: 1.3846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "veeZFDKT8qdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3c3c6a4a-547f-4439-b9c3-2a654447dd15"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "metadata": {
        "id": "PgbYpfNT8xZt"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "#attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, decoder_outputs2])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "metadata": {
        "id": "MQybBLPs80AF"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "rdftUTMB85WO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "HkJ9NqNr9KS4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "for i in range(0,29):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "zRFTEZPg9M_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f938e595-17c7-4bdd-e458-ad01d1b2e3c1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: consistent product buying year also purchased gift family members want bp lowering properties \n",
            "Original summary: love this tea \n",
            "1/1 [==============================] - 1s 645ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: extraordinary crunchy tender tasty use salads added last minute like croutons also terrific snacks \n",
            "Original summary: amazing snack \n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  great snack\n",
            "\n",
            "\n",
            "Review: add nibs smoothies yogurts everyone family enjoys product including month old son however cacao nibs sweet would consider candy \n",
            "Original summary: not candy \n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: lived southern germany years loved egg noodles comes closest homemade german spaetzle packaged product tried save lot money buying case qualify free shipping long shelf life \n",
            "Original summary: taste of germany \n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  best ever\n",
            "\n",
            "\n",
            "Review: like first foremost healthy organic stuffed full preservatives also trust newman products always loved salad dressings pasta sauces make top quality first dog know make treats little different past loves looks sounds tasty crunchy continue purchase dog \n",
            "Original summary: my dog loves them \n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  my dog loves these\n",
            "\n",
            "\n",
            "Review: based local source tea amazon price bargain almost rd less daily tea drinker tea choice like strong rishi earl grey loose tea brew strong like never bitter metallic chemical flavors either tins useful bonus around house highly recommended \n",
            "Original summary: not too not too much bergamot just right \n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  good tea\n",
            "\n",
            "\n",
            "Review: dromedary gingerbread mix best available unfortunately product available supermarkets west coast \n",
            "Original summary: gingerbread \n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  best ever\n",
            "\n",
            "\n",
            "Review: first coffee got great logo cap anybody resist cup black tiger seriously though makes great cup dark rich without bitter makes excellent large mug morning coffee got one order list pick every month well worth enjoy strong cup \n",
            "Original summary: strong rich flavors in dark roast \n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: bitter forewarned try mix consume straight recommend using gel caps filling raw powder delicate little taste buds otherwise mixing juice smoothies etc help nice need little boost \n",
            "Original summary: zip \n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  good stuff\n",
            "\n",
            "\n",
            "Review: like organic stuff sweet like drinking sugar sweetness overwhelming could hardly drink waste mixed concentrate milk next time try slightly sweet concentrate instead \n",
            "Original summary: ugh \n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  not bad\n",
            "\n",
            "\n",
            "Review: visiting cayman islands cruise coming back one pack tortuga chocolate cake decided get pack give friends also try key lime original golden cakes key lime definitely much better expected note individual cake packets suited people price pack cruise ship one less amazon carries \n",
            "Original summary: good assortment \n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  best chocolate ever\n",
            "\n",
            "\n",
            "Review: feeding dog good treats since line came loves \n",
            "Original summary: our dog loves them \n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  my dog loves these\n",
            "\n",
            "\n",
            "Review: unfortunately dried mangos pictured instead smaller bite size pieces pictured described soft light reviews received sliced version seems little drier chewier expected also much flavor brands purchased bad though excellent price quantity even better purchased subscribe save \n",
            "Original summary: not bad for good price \n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  not as good as the original\n",
            "\n",
            "\n",
            "Review: everyone else seems reviewing shipping product switch gears review product love grew eating stuff still occasion tastes little grown though like make poached eggs hot sauce break eggs open let yolk act sauce chicken noodles yum good kid maruchan done smart thing fixing something broken glad stayed less wish sodium msg contents high suppose really way around remedy often throw flavour packet season noodles \n",
            "Original summary: good ol ramen \n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  good stuff\n",
            "\n",
            "\n",
            "Review: boyfriend pleased receive christmas tastes great little kick definitely reorder \n",
            "Original summary: very good jerky \n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: buying food locally began hard time finding searched online little cost effective pups seem love food \n",
            "Original summary: just what was expected \n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: pretty good flour mix however bean aftertaste like bread however wonderful breading chicken fish ok cakes like chocolate flavors hide bean taste \n",
            "Original summary: pretty good flour \n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  good but not great\n",
            "\n",
            "\n",
            "Review: pg tips tea looking loyal empress tea blend empress hotel victoria bc economy changing became unaffordable purchase directly canada anyway fine comparable tea blend smooth rich flavor much stronger delicious american teas love especially milk sugar disappointed looking stronger richer tea \n",
            "Original summary: excellent tea blend \n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  best tea ever\n",
            "\n",
            "\n",
            "Review: drawer opens closes easily saw reviews keurig opening underneath cabinet problem pulled keurig good go price also reasonable glad ordered \n",
            "Original summary: love this \n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: nd time ordered flowers mother times beautiful lasted weeks plentiful happy times mother well worth \n",
            "Original summary: flowers \n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  great gift\n",
            "\n",
            "\n",
            "Review: used showers baby birthday parties tie five six ribbon give favors people generally like fact natural \n",
            "Original summary: for parties \n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  great for kids\n",
            "\n",
            "\n",
            "Review: breads anna saving grace people want eat healthy special dietary needs husband diagnosed celiac years ago truly best brand friends come bring sandwiches picnic nobody notices bread gluten free opposite start baking bread good taste healthy ingredients always selection different bread mixes home husband goes gaga chicken pot pie recipe anna made pie crust much became running joke friends \n",
            "Original summary: amazing bread \n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted summary:  best gf bread mix\n",
            "\n",
            "\n",
            "Review: great anytime snack especially love cheese taste every bite easy way bowl popcorn pop microwave really pleases flat microwave popcorn taste like brands smells appetizing \n",
            "Original summary: pleasing \n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  great snack\n",
            "\n",
            "\n",
            "Review: like mustard based barbecue sauce one great pulled chicken pork \n",
            "Original summary: absolutely delicious \n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  great sauce\n",
            "\n",
            "\n",
            "Review: coffee addict got diagnosed gerd success curing reluctantly went coffee looked postum grain coffee substitute childhood find ceased production digging discovered cafix quite nice tasting tough days able drink morning alot pleasure nothing beats real thing need without coffee think cafix best bet natural instant beverage ounce packages \n",
            "Original summary: cafix coffee substitute \n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted summary:  great coffee\n",
            "\n",
            "\n",
            "Review: feeding cats evo three years changing food year three cats older cat picky eater fed food immediately liked better food given also lot energy amazing could believe started running around house chasing little fur batting around cats like well food protein beware warnings consult vet cat kidney problems \n",
            "Original summary: best dry cat food and have tried lot of them \n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  my cats love this food\n",
            "\n",
            "\n",
            "Review: catsup good bit runny consistency regular catsup buy learned make catsup tomato paste stevia add little horseradish lemon dash mustard got wonderful cocktail sauce \n",
            "Original summary: good stuff \n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted summary:  good stuff\n",
            "\n",
            "\n",
            "Review: solid delicious hold flavor steeps th weak steep possible package received labeled organic although reflected item details price excellent easily pay lb comparable quality especially purchased smaller quantity packages top line luxury oolong much better many offered price range \n",
            "Original summary: incredible value \n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: expected coffee could used standard coffee maker \n",
            "Original summary: senseo coffee \n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted summary:  not good\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "print('BLEU score -> {}'.format(sentence_bleu(seq2summary(y_tr[-4]).split(), decode_sequence(x_tr[-4].reshape(1,max_text_len)).split())))"
      ],
      "metadata": {
        "id": "5vBdDWXhAnqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f7806e-fc7f-464a-ca0f-14f340ee0fcc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 161ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "BLEU score -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wWrfMrSTDEvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/attention.py\""
      ],
      "metadata": {
        "id": "vHuLQAYN_J66"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}